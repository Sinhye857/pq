#include <iostream>
#include <fstream>
#include <string>
#include <vector>
#include <unordered_map>
#include <unordered_set>
#include <sstream>
#include <algorithm>
#include <cmath>
#include <cctype>
#include <chrono>
#include <iomanip>
#include <random>
#include <numeric>
#include <omp.h>

using namespace std;
using namespace std::chrono;

// 数据结构定义
struct Movie {
    int id;
    string title;
    vector<string> genres;
};

struct User {
    int id;
    unordered_map<int, double> ratings;
    unordered_map<string, int> tags;
    unordered_map<string, double> genre_prefs;
    vector<double> feature_vec;
    vector<uint8_t> pq_codes;
    double avg_rating = 0;
};

// PQ参数配置
const int PQ_M = 8;              // 子空间数量
const int PQ_K = 256;            // 每子空间聚类数
const int FEATURE_DIM = 40;      // 特征向量维度
vector<vector<vector<double>>> pq_codebooks;

// 复杂度分析
struct Complexity {
    int user_count = 0;
    int movie_count = 0;
    int rating_count = 0;
    int tag_count = 0;
    double load_time = 0;
    double pq_train_time = 0;
    double pq_encode_time = 0;
    double recommend_time = 0;
};

// 工具函数
vector<string> read_lines(const string& path) {
    ifstream file(path, ios::binary | ios::ate);
    if (!file.is_open()) return {};

    const size_t file_size = file.tellg();
    file.seekg(0);

    string buffer(file_size, '\0');
    file.read(&buffer[0], file_size);

    vector<string> lines;
    size_t pos = 0;
    while (pos < buffer.size()) {
        size_t end = buffer.find('\n', pos);
        lines.emplace_back(buffer.substr(pos, end - pos));
        pos = (end == string::npos) ? buffer.size() : end + 1;
    }
    return lines;
}

// 快速解析整数（比 stoi 快 3-5 倍）
int fast_atoi(const char* str, const char** endptr = nullptr) {
    int val = 0;
    while (*str >= '0' && *str <= '9') {
        val = val * 10 + (*str - '0');
        ++str;
    }
    if (endptr) *endptr = str;
    return val;
}

// 快速解析浮点数（比 stod 快 2-3 倍）
double fast_atof(const char* str) {
    double val = 0.0, factor = 1.0;
    int sign = 1;

    if (*str == '-') { sign = -1; ++str; }
    while (*str >= '0' && *str <= '9') {
        val = val * 10 + (*str - '0');
        ++str;
    }
    if (*str == '.') {
        ++str;
        while (*str >= '0' && *str <= '9') {
            val += (*(str++) - '0') * (factor *= 0.1);
        }
    }
    return val * sign;
}

vector<string> split(const string& s, const string& delim) {
    vector<string> tokens;
    size_t pos = 0, delim_len = delim.length();
    while (pos < s.length()) {
        size_t found = s.find(delim, pos);
        if (found == string::npos) found = s.length();
        tokens.push_back(s.substr(pos, found - pos));
        pos = found + delim_len;
    }
    return tokens;
}

// 数据加载函数
unordered_map<int, Movie> load_movies(const string& path, Complexity& analysis) {
    auto start = high_resolution_clock::now();
    unordered_map<int, Movie> movies;

    for (const string& line : read_lines(path)) {
        vector<string> parts = split(line, "::");
        if (parts.size() < 3) continue;

        Movie m;
        m.id = stoi(parts[0]);
        m.title = parts[1];
        m.genres = split(parts[2], "|");
        movies[m.id] = m;
        analysis.movie_count++;
    }

    analysis.load_time += duration_cast<milliseconds>(
        high_resolution_clock::now() - start).count() / 1000.0;
    return movies;
}

void process_ratings(User& user, const unordered_map<int, Movie>& movies) {
    double total = 0;
    unordered_map<string, double> genre_sum;
    unordered_map<string, int> genre_cnt;

    for (const auto& rating_pair : user.ratings) {
        total += rating_pair.second;
        auto movie_it = movies.find(rating_pair.first);
        if (movie_it != movies.end()) {
            for (const string& g : movie_it->second.genres) {
                genre_sum[g] += rating_pair.second;
                genre_cnt[g]++;
            }
        }
    }

    if (!user.ratings.empty()) {
        user.avg_rating = total / user.ratings.size();
        for (const auto& genre_pair : genre_cnt) {
            user.genre_prefs[genre_pair.first] = genre_sum[genre_pair.first] / genre_pair.second;
        }
    }
}

void load_ratings(const string& path,
    unordered_map<int, User>& users_map,
    unordered_map<int, vector<int>>& movie_users,
    const unordered_map<int, Movie>& movies,
    Complexity& analysis)
{
    auto start = high_resolution_clock::now();
    auto lines = read_lines(path);
    analysis.rating_count = lines.size();

    // 第一遍：收集所有 UID 并预分配内存
    vector<int> uids;
#pragma omp parallel for
    for (int i = 0; i < static_cast<int>(lines.size()); ++i) {
        const char* line = lines[i].c_str();
        int uid = fast_atoi(line);
#pragma omp critical
        {
            if (users_map.find(uid) == users_map.end()) {
                users_map[uid].id = uid;
                uids.push_back(uid);
            }
        }
    }

    // 第二遍：并行解析评分数据
#pragma omp parallel
    {
        // 每个线程维护本地数据避免锁竞争
        unordered_map<int, User> local_users;
        unordered_map<int, vector<int>> local_movie_users;

#pragma omp for nowait
        for (int i = 0; i < static_cast<int>(lines.size()); ++i) {
            const char* line = lines[i].c_str();
            const char* p = line;

            // 解析 UID
            int uid = fast_atoi(p, &p);
            p += 2; // 跳过 "::"

            // 解析 MID
            int mid = fast_atoi(p, &p);
            p += 2; // 跳过 "::"

            // 解析 Rating
            double rating = fast_atof(p);

            // 更新本地数据
            local_users[uid].ratings[mid] = rating;
            local_movie_users[mid].push_back(uid);
        }

        // 合并到全局数据结构
#pragma omp critical
        {
            for (auto& [uid, user] : local_users) {
                users_map[uid].ratings.merge(user.ratings);
            }
            for (auto& [mid, uids] : local_movie_users) {
                movie_users[mid].insert(movie_users[mid].end(), uids.begin(), uids.end());
            }
        }
    }

    // 并行处理用户数据（计算平均评分等）
    vector<User*> user_ptrs;
    for (auto& [uid, user] : users_map) {
        user_ptrs.push_back(&user);
    }

#pragma omp parallel for
    for (int i = 0; i < static_cast<int>(user_ptrs.size()); ++i) {
        User* user = user_ptrs[i];
        double total = 0;
        unordered_map<string, double> genre_sum;
        unordered_map<string, int> genre_cnt;

        for (auto& [mid, rating] : user->ratings) {
            total += rating;
            auto it = movies.find(mid);
            if (it != movies.end()) {
                for (const string& g : it->second.genres) {
                    genre_sum[g] += rating;
                    genre_cnt[g]++;
                }
            }
        }

        user->avg_rating = total / user->ratings.size();
        for (auto& [g, cnt] : genre_cnt) {
            user->genre_prefs[g] = genre_sum[g] / cnt;
        }
    }

    analysis.load_time += duration_cast<milliseconds>(
        high_resolution_clock::now() - start).count() / 1000.0;
    analysis.user_count = users_map.size();
}
void load_tags(const string& path, unordered_map<int, User>& users, Complexity& analysis) {
    auto start = high_resolution_clock::now();

    for (const string& line : read_lines(path)) {
        analysis.tag_count++;
        vector<string> parts = split(line, "::");
        if (parts.size() < 4) continue;

        int uid = stoi(parts[0]);
        string tag = parts[2];
        transform(tag.begin(), tag.end(), tag.begin(), ::tolower);

        users[uid].tags[tag]++;
    }

    analysis.load_time += duration_cast<milliseconds>(
        high_resolution_clock::now() - start).count() / 1000.0;
}

// 特征工程
const vector<string> GENRE_LIST = {
    "Action", "Adventure", "Animation", "Children", "Comedy",
    "Crime", "Documentary", "Drama", "Fantasy", "Film-Noir",
    "Horror", "Musical", "Mystery", "Romance", "Sci-Fi",
    "Thriller", "War", "Western"
};

void build_feature_vector(User& user) {
    vector<double> features(FEATURE_DIM, 0.0);
    int idx = 0;

    // 平均评分（标准化）
    features[idx++] = user.avg_rating / 5.0;

    // 类型偏好
    for (const auto& genre : GENRE_LIST) {
        auto it = user.genre_prefs.find(genre);
        features[idx++] = (it != user.genre_prefs.end()) ? (it->second / 5.0) : 0.0;
    }

    // 标签频率（取前20）
    vector<pair<string, int>> tag_counts(user.tags.begin(), user.tags.end());
    partial_sort(tag_counts.begin(), tag_counts.begin() + min(20, (int)tag_counts.size()),
        tag_counts.end(), [](auto& a, auto& b) { return a.second > b.second; });

    for (int i = 0; i < 20; ++i) {
        features[idx++] = (i < tag_counts.size()) ? (tag_counts[i].second / 10.0) : 0.0;
    }

    user.feature_vec = features;
}

// PQ核心算法
vector<vector<double>> kmeans_subspace(const vector<vector<double>>& data, int k, int max_iter = 15) {
    random_device rd;
    mt19937 gen(rd());
    uniform_int_distribution<> init(0, data.size() - 1);

    // 初始化质心
    vector<vector<double>> centroids(k);
    for (int i = 0; i < k; ++i) {
        centroids[i] = data[init(gen)];
    }

    vector<int> labels(data.size());
    for (int iter = 0; iter < max_iter; ++iter) {
        // 分配样本
#pragma omp parallel for
        for (int i = 0; i < data.size(); ++i) {
            double min_dist = numeric_limits<double>::max();
            int best_cluster = 0;
            for (int j = 0; j < k; ++j) {
                double dist = 0.0;
                for (size_t d = 0; d < data[i].size(); ++d) {
                    double diff = data[i][d] - centroids[j][d];
                    dist += diff * diff;
                }
                if (dist < min_dist) {
                    min_dist = dist;
                    best_cluster = j;
                }
            }
            labels[i] = best_cluster;
        }

        // 并行更新质心
        vector<vector<vector<double>>> local_centroids(omp_get_max_threads(),
            vector<vector<double>>(k, vector<double>(data[0].size(), 0)));
        vector<vector<int>> local_counts(omp_get_max_threads(), vector<int>(k, 0));

#pragma omp parallel for
        for (int i = 0; i < data.size(); ++i) {
            int tid = omp_get_thread_num();
            int cluster = labels[i];
            for (int d = 0; d < data[i].size(); ++d) {
                local_centroids[tid][cluster][d] += data[i][d];
            }
            local_counts[tid][cluster]++;
        }

        // 合并各线程结果
        vector<vector<double>> new_centroids(k, vector<double>(data[0].size(), 0));
        vector<int> counts(k, 0);
        for (int t = 0; t < omp_get_max_threads(); ++t) {
            for (int j = 0; j < k; ++j) {
                counts[j] += local_counts[t][j];
                for (size_t d = 0; d < data[0].size(); ++d) {
                    new_centroids[j][d] += local_centroids[t][j][d];
                }
            }
        }

        // 标准化质心
#pragma omp parallel for
        for (int j = 0; j < k; ++j) {
            if (counts[j] > 0) {
                for (size_t d = 0; d < new_centroids[j].size(); ++d) {
                    new_centroids[j][d] /= counts[j];
                }
            }
        }
        centroids = move(new_centroids);
    }
    return centroids;
}

void train_pq_codebooks(const vector<User>& users, Complexity& analysis) {
    auto start = high_resolution_clock::now();

    vector<vector<double>> features;
    for (const auto& user : users) {
        features.push_back(user.feature_vec);
    }

    int sub_dim = FEATURE_DIM / PQ_M;
    pq_codebooks.resize(PQ_M);

#pragma omp parallel for
    for (int m = 0; m < PQ_M; ++m) {
        vector<vector<double>> subspace_data;
        for (const auto& vec : features) {
            vector<double> sub(vec.begin() + m * sub_dim,
                (m + 1 == PQ_M) ? vec.end() : vec.begin() + (m + 1) * sub_dim);
            subspace_data.push_back(sub);
        }
        pq_codebooks[m] = kmeans_subspace(subspace_data, PQ_K);
    }

    analysis.pq_train_time = duration_cast<milliseconds>(
        high_resolution_clock::now() - start).count() / 1000.0;
}

void pq_encode_users(vector<User>& users) {
    auto start = high_resolution_clock::now();
    int sub_dim = FEATURE_DIM / PQ_M;

    vector<User*> user_ptrs;
    for (auto& user : users) {
        user_ptrs.push_back(&user);
    }

#pragma omp parallel for
    for (int i = 0; i < user_ptrs.size(); ++i) {
        User& user = *user_ptrs[i];
        user.pq_codes.resize(PQ_M);
        for (int m = 0; m < PQ_M; ++m) {
            vector<double> sub_vec(user.feature_vec.begin() + m * sub_dim,
                (m + 1 == PQ_M) ? user.feature_vec.end() : user.feature_vec.begin() + (m + 1) * sub_dim);

            double min_dist = numeric_limits<double>::max();
            uint8_t best_code = 0;
            for (int k = 0; k < PQ_K; ++k) {
                double dist = 0.0;
                for (size_t d = 0; d < sub_vec.size(); ++d) {
                    double diff = sub_vec[d] - pq_codebooks[m][k][d];
                    dist += diff * diff;
                }
                if (dist < min_dist) {
                    min_dist = dist;
                    best_code = k;
                }
            }
            user.pq_codes[m] = best_code;
        }
    }
}

double pq_similarity(const User& u1, const User& u2) {
    double sim = 0.0;
    int sub_dim = FEATURE_DIM / PQ_M;

    for (int m = 0; m < PQ_M; ++m) {
        const auto& c1 = pq_codebooks[m][u1.pq_codes[m]];
        const auto& c2 = pq_codebooks[m][u2.pq_codes[m]];

        for (int d = 0; d < sub_dim; ++d) {
            sim += c1[d] * c2[d];
        }
    }
    return sim / (PQ_M * sub_dim);
}

vector<pair<int, double>> generate_recommendations(
    int target_uid,
    const vector<User>& users,
    const unordered_map<int, vector<int>>& movie_users,
    const unordered_map<int, Movie>& movies,
    Complexity& analysis)
{
    auto start = high_resolution_clock::now();

    // 获取目标用户在 vector 中的索引
    const User& target = users[target_uid];
    unordered_set<int> rated_movies;
    for (const auto& [mid, _] : target.ratings) {
        rated_movies.insert(mid);
    }

    vector<pair<int, double>> recommendations;
    vector<const Movie*> movie_list;
    for (const auto& [mid, movie] : movies) {
        movie_list.push_back(&movie);
    }

    const long long num_movies = static_cast<long long>(movie_list.size());
    recommendations.reserve(num_movies);

#pragma omp parallel for
    for (long long i = 0; i < num_movies; ++i) {
        const Movie* movie = movie_list[i];
        int mid = movie->id;
        if (rated_movies.count(mid)) continue;

        double sum_sim = 0.0, weighted_sum = 0.0;
        auto movie_users_it = movie_users.find(mid);
        if (movie_users_it != movie_users.end()) {
            // 直接使用 vector 索引访问用户
            for (int other_index : movie_users_it->second) {
                if (other_index < 0 || other_index >= users.size()) {
                    continue; // 边界检查
                }
                const User& other = users[other_index];
                if (other.id == target.id) continue; // 跳过自己

                double sim = pq_similarity(target, other);
                if (sim > 0) {
                    auto rating_it = other.ratings.find(mid);
                    if (rating_it != other.ratings.end()) {
                        double diff = rating_it->second - other.avg_rating;
                        weighted_sum += sim * diff;
                        sum_sim += sim;
                    }
                }
            }
        }

        double pred = (sum_sim > 1e-6) ? (target.avg_rating + weighted_sum / sum_sim) : 0;
#pragma omp critical
        {
            recommendations.emplace_back(mid, pred);
        }
    }

    // 排序并返回结果
    sort(recommendations.begin(), recommendations.end(),
        [](const pair<int, double>& a, const pair<int, double>& b) {
            return a.second > b.second;
        });

    analysis.recommend_time = duration_cast<milliseconds>(
        high_resolution_clock::now() - start).count() / 1000.0;

    if (recommendations.size() > 10) {
        recommendations.resize(10);
    }
    return recommendations;
}
int main() {
    Complexity analysis;
    auto total_start = high_resolution_clock::now();

    auto movies = load_movies("movies.dat", analysis);
    unordered_map<int, User> users_map;
    unordered_map<int, vector<int>> movie_users;

    try {
        load_ratings("ratings.dat", users_map, movie_users, movies, analysis);
        load_tags("tags.dat", users_map, analysis);
    }
    catch (const exception& e) {
        cerr << "数据加载错误: " << e.what() << endl;
        return 1;
    }

    vector<User> users;
    unordered_map<int, int> uid_map;
    for (auto& user_pair : users_map) {
        uid_map[user_pair.first] = users.size();
        build_feature_vector(user_pair.second);
        users.push_back(move(user_pair.second));
    }

    auto pq_start = high_resolution_clock::now();
    train_pq_codebooks(users, analysis);
    pq_encode_users(users);
    analysis.pq_encode_time = duration_cast<milliseconds>(
        high_resolution_clock::now() - pq_start).count() / 1000.0;

    if (!users.empty()) {
        int target_uid = users.front().id;
        int target_idx = uid_map[target_uid];
        cout << "\n为用户 " << target_uid << " 生成推荐..." << endl;

        auto recommendations = generate_recommendations(target_idx, users, movie_users, movies, analysis);

        cout << "\nTOP 10 推荐结果:" << endl;
        for (const auto& [mid, score] : recommendations) {
            auto movie_it = movies.find(mid);
            if (movie_it != movies.end()) {
                cout << "  [" << setw(4) << mid << "] " << left << setw(40)
                    << movie_it->second.title.substr(0, 40)
                    << " 预测评分: " << fixed << setprecision(2) << score << endl;
            }
        }
    }

    cout << "\n=== 性能分析 ===" << endl;
    cout << "数据统计:" << endl;
    cout << "用户数: " << analysis.user_count << endl;
    cout << "电影数: " << analysis.movie_count << endl;
    cout << "评分记录: " << analysis.rating_count << endl;
    cout << "标签数: " << analysis.tag_count << endl;

    cout << "\n时间消耗:" << endl;
    cout << "数据加载: " << analysis.load_time << "秒" << endl;
    cout << "PQ训练: " << analysis.pq_train_time << "秒" << endl;
    cout << "PQ编码: " << analysis.pq_encode_time << "秒" << endl;
    cout << "推荐生成: " << analysis.recommend_time << "秒" << endl;

    cout << "\n总耗时: " << duration_cast<milliseconds>(
        high_resolution_clock::now() - total_start).count() / 1000.0 << "秒" << endl;

    return 0;
}
