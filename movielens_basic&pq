#include <iostream>
#include <fstream>
#include <string>
#include <vector>
#include <unordered_map>
#include <unordered_set>
#include <sstream>
#include <algorithm>
#include <cmath>
#include <cctype>
#include <chrono>
#include <iomanip>
#include <random>
#include <limits>
#include <cassert>

using namespace std;
using namespace std::chrono;

// 数据结构定义
struct Movie {
    int id;
    string title;
    vector<string> genres;
};

struct User {
    int id;
    unordered_map<int, double> ratings;
    unordered_map<string, int> tags;
    unordered_map<string, double> genre_prefs;
    double avg_rating = 0;
    vector<float> feature; // 新增：用户特征向量
};

// 复杂度分析结构体
struct Complexity {
    int user_count = 0;
    int movie_count = 0;
    int rating_count = 0;
    int tag_count = 0;
    double load_time = 0;
    double recommend_time = 0;
};

// PQ相关结构体和类
struct KMeansResult {
    vector<vector<float>> centers;
    vector<int> assignments;
};

class ProductQuantization {
private:
    int d, m, k, sub_dim;
    vector<KMeansResult> cluster_results;
    vector<vector<int>> codebook_A;
    vector<vector<vector<float>>> distance_tables_B;

    vector<vector<vector<float>>> split_into_subspaces(const vector<vector<float>>& data) {
        vector<vector<vector<float>>> subspaces(m);
        for (const auto& point : data) {
            for (int i = 0; i < m; ++i) {
                int start = i * sub_dim;
                vector<float> sub_point(point.begin() + start, point.begin() + start + sub_dim);
                subspaces[i].push_back(sub_point);
            }
        }
        return subspaces;
    }

    vector<vector<int>> build_codebook_A(const vector<KMeansResult>& results) {
        vector<vector<int>> A(m, vector<int>(results[0].assignments.size()));
        for (int i = 0; i < m; ++i)
            A[i] = results[i].assignments;
        return A;
    }

    vector<vector<vector<float>>> precompute_distance_tables() {
        vector<vector<vector<float>>> tables(m);
        for (int i = 0; i < m; ++i) {
            auto& centers = cluster_results[i].centers;
            int k = centers.size();
            tables[i].resize(k, vector<float>(k));
            for (int j = 0; j < k; ++j)
                for (int l = 0; l < k; ++l)
                    tables[i][j][l] = squared_euclidean_distance(centers[j], centers[l]);
        }
        return tables;
    }

public:
    ProductQuantization(int d, int m, int k) : d(d), m(m), k(k) {
        assert(d % m == 0);
        sub_dim = d / m;
    }

    void train(const vector<vector<float>>& data) {
        auto subspaces = split_into_subspaces(data);
        cluster_results.resize(m);
        for (int i = 0; i < m; ++i)
            cluster_results[i] = k_means(subspaces[i], k);
        codebook_A = build_codebook_A(cluster_results);
        distance_tables_B = precompute_distance_tables();
    }

    // 新增：获取编码簿和距离表
    const vector<vector<int>>& get_codebook_A() const { return codebook_A; }
    const vector<vector<vector<float>>>& get_distance_tables_B() const { return distance_tables_B; }

    static float squared_euclidean_distance(const vector<float>& a, const vector<float>& b) {
        float sum = 0.0f;
        for (size_t i = 0; i < a.size(); ++i) {
            float diff = a[i] - b[i];
            sum += diff * diff;
        }
        return sum;
    }

    static KMeansResult k_means(const vector<vector<float>>& data, int k, int max_iters = 100) {
        int n = data.size();
        int dim = data[0].size();

        random_device rd;
        mt19937 gen(rd());
        uniform_int_distribution<> distrib(0, n - 1);

        vector<vector<float>> centers(k);
        for (int i = 0; i < k; ++i)
            centers[i] = data[distrib(gen)];

        vector<int> assignments(n);
        for (int iter = 0; iter < max_iters; ++iter) {
            bool changed = false;
            for (int i = 0; i < n; ++i) {
                float min_dist = numeric_limits<float>::max();
                int best_c = 0;
                for (int c = 0; c < k; ++c) {
                    float dist = squared_euclidean_distance(data[i], centers[c]);
                    if (dist < min_dist) {
                        min_dist = dist;
                        best_c = c;
                    }
                }
                if (assignments[i] != best_c) {
                    assignments[i] = best_c;
                    changed = true;
                }
            }
            if (!changed) break;

            vector<vector<float>> new_centers(k, vector<float>(dim, 0));
            vector<int> counts(k, 0);
            for (int i = 0; i < n; ++i) {
                int c = assignments[i];
                for (int d = 0; d < dim; ++d)
                    new_centers[c][d] += data[i][d];
                counts[c]++;
            }
            for (int c = 0; c < k; ++c) {
                if (counts[c] == 0) continue;
                for (int d = 0; d < dim; ++d)
                    new_centers[c][d] /= counts[c];
            }
            centers = new_centers;
        }
        return { centers, assignments };
    }
};

// 工具函数
vector<string> read_lines(const string& path) {
    vector<string> lines;
    ifstream file(path);
    if (file.is_open()) {
        string line;
        while (getline(file, line)) {
            if (!line.empty()) lines.push_back(line);
        }
    }
    return lines;
}

vector<string> split(const string& s, const string& delim) {
    vector<string> tokens;
    size_t pos = 0, delim_len = delim.length();
    while (pos < s.length()) {
        size_t found = s.find(delim, pos);
        if (found == string::npos) found = s.length();
        tokens.push_back(s.substr(pos, found - pos));
        pos = found + delim_len;
    }
    return tokens;
}

// 数据加载函数
unordered_map<int, Movie> load_movies(const string& path, Complexity& analysis) {
    auto start = high_resolution_clock::now();
    unordered_map<int, Movie> movies;
    for (const string& line : read_lines(path)) {
        auto parts = split(line, "::");
        if (parts.size() < 3) continue;
        Movie m;
        m.id = stoi(parts[0]);
        m.title = parts[1];
        m.genres = split(parts[2], "|");
        movies[m.id] = m;
        analysis.movie_count++;
    }
    auto end = high_resolution_clock::now();
    analysis.load_time += duration_cast<milliseconds>(end - start).count() / 1000.0;
    return movies;
}

void load_ratings(const string& path, unordered_map<int, User>& users, unordered_map<int, vector<int>>& movie_users,
    const unordered_map<int, Movie>& movies, Complexity& analysis) {
    auto start = high_resolution_clock::now();
    for (const string& line : read_lines(path)) {
        analysis.rating_count++;
        auto parts = split(line, "::");
        if (parts.size() < 4) continue;
        int uid = stoi(parts[0]);
        int mid = stoi(parts[1]);
        double rating = stod(parts[2]);
        users[uid].id = uid;
        users[uid].ratings[mid] = rating;
        movie_users[mid].push_back(uid);
    }
    for (auto& [uid, user] : users) {
        double total = 0;
        unordered_map<string, double> genre_sum;
        unordered_map<string, int> genre_cnt;
        for (const auto& [mid, rating] : user.ratings) {
            total += rating;
            if (movies.count(mid)) {
                for (const string& g : movies.at(mid).genres) {
                    genre_sum[g] += rating;
                    genre_cnt[g]++;
                }
            }
        }
        user.avg_rating = total / user.ratings.size();
        for (const auto& [g, cnt] : genre_cnt) {
            user.genre_prefs[g] = genre_sum[g] / cnt;
        }
    }
    auto end = high_resolution_clock::now();
    analysis.load_time += duration_cast<milliseconds>(end - start).count() / 1000.0;
    analysis.user_count = users.size();
}

void load_tags(const string& path, unordered_map<int, User>& users, Complexity& analysis) {
    auto start = high_resolution_clock::now();
    for (const string& line : read_lines(path)) {
        analysis.tag_count++;
        auto parts = split(line, "::");
        if (parts.size() < 4) continue;
        int uid = stoi(parts[0]);
        string tag = parts[2];
        transform(tag.begin(), tag.end(), tag.begin(), ::tolower);
        users[uid].tags[tag]++;
    }
    auto end = high_resolution_clock::now();
    analysis.load_time += duration_cast<milliseconds>(end - start).count() / 1000.0;
}

// 构建用户特征向量并训练PQ模型
void build_features_and_train_pq(
    unordered_map<int, User>& users,
    const unordered_map<int, Movie>& movies,
    ProductQuantization*& pq,
    vector<int>& user_ids,
    unordered_map<int, int>& uid_to_index,
    Complexity& analysis) {

    auto start = high_resolution_clock::now();

    // ================== 收集所有电影类型 ==================
    unordered_set<string> all_genres;
    for (const auto& [mid, movie] : movies) {
        for (const string& g : movie.genres) {
            all_genres.insert(g);
        }
    }
    vector<string> genre_list(all_genres.begin(), all_genres.end());
    sort(genre_list.begin(), genre_list.end());

    // ================== 收集前100个常用标签 ==================
    const int TOP_TAGS = 100;
    unordered_map<string, int> tag_counts;
    for (const auto& [uid, user] : users) {
        for (const auto& [tag, cnt] : user.tags) {
            tag_counts[tag] += cnt;
        }
    }

    vector<pair<string, int>> tag_list(tag_counts.begin(), tag_counts.end());
    sort(tag_list.begin(), tag_list.end(),
        [](const auto& a, const auto& b) { return a.second > b.second; });

    vector<string> selected_tags;
    for (int i = 0; i < TOP_TAGS && i < tag_list.size(); ++i) {
        selected_tags.push_back(tag_list[i].first);
    }

    // ================== 计算原始特征维度 ==================
    const int original_dim = genre_list.size() + selected_tags.size() + 1;
    const int SUBSPACES = 8;

    // ================== 自动填充特征维度 ==================
    const int padding = (SUBSPACES - (original_dim % SUBSPACES)) % SUBSPACES;
    const int feature_dim = original_dim + padding;

    // ================== 构建用户特征向量 ==================
    vector<vector<float>> user_features;
    user_ids.reserve(users.size());
    uid_to_index.reserve(users.size());

    for (const auto& [uid, user] : users) {
        user_ids.push_back(uid);
        uid_to_index[uid] = user_features.size();

        vector<float> feature;
        feature.reserve(feature_dim);

        // 类型偏好（归一化）
        for (const string& genre : genre_list) {
            auto it = user.genre_prefs.find(genre);
            feature.push_back(it != user.genre_prefs.end()
                ? static_cast<float>(it->second / 5.0)
                : 0.0f);
        }

        // 标签出现次数
        for (const string& tag : selected_tags) {
            auto it = user.tags.find(tag);
            feature.push_back(it != user.tags.end()
                ? static_cast<float>(it->second)
                : 0.0f);
        }

        // 平均评分（归一化到0-1）
        feature.push_back(static_cast<float>((user.avg_rating - 1.0) / 4.0));

        // 填充零到目标维度
        feature.resize(feature_dim, 0.0f);

        user_features.push_back(move(feature));
    }

    // ================== 训练PQ模型 ==================
    const int CLUSTERS = 256;
    pq = new ProductQuantization(feature_dim, SUBSPACES, CLUSTERS);
    pq->train(user_features);

    auto end = high_resolution_clock::now();
    analysis.load_time += duration_cast<milliseconds>(end - start).count() / 1000.0;
}

// 生成推荐
vector<pair<int, double>> generate_recommendations(
    int uid,
    const unordered_map<int, User>& users,
    const unordered_map<int, vector<int>>& movie_users,
    const unordered_map<int, Movie>& movies,
    const ProductQuantization& pq,
    const unordered_map<int, int>& uid_to_index,
    const vector<int>& user_ids,
    Complexity& analysis) {

    auto start = high_resolution_clock::now();
    vector<pair<int, double>> recommendations;

    const User& target = users.at(uid);
    unordered_set<int> rated;
    for (const auto& [mid, _] : target.ratings) rated.insert(mid);

    // 获取目标用户的PQ索引
    int target_idx = uid_to_index.at(uid);

    for (const auto& [mid, movie] : movies) {
        if (rated.count(mid)) continue;

        double sum_sim = 0, weighted_sum = 0;
        if (movie_users.count(mid)) {
            for (int other_uid : movie_users.at(mid)) {
                if (other_uid == uid) continue;

                // 使用PQ加速相似度计算
                int other_idx = uid_to_index.at(other_uid);
                float dist = 0;
                for (int i = 0; i < pq.get_codebook_A().size(); ++i) {
                    int c_target = pq.get_codebook_A()[i][target_idx];
                    int c_other = pq.get_codebook_A()[i][other_idx];
                    dist += pq.get_distance_tables_B()[i][c_target][c_other];
                }
                double sim = 1.0 / (1.0 + dist);

                const User& other = users.at(other_uid);
                double diff = other.ratings.at(mid) - other.avg_rating;
                weighted_sum += sim * diff;
                sum_sim += sim;
            }
        }

        double pred = sum_sim ? target.avg_rating + (weighted_sum / sum_sim) : 0;
        recommendations.emplace_back(mid, pred);
    }

    sort(recommendations.begin(), recommendations.end(),
        [](const auto& a, const auto& b) { return a.second > b.second; });

    auto end = high_resolution_clock::now();
    analysis.recommend_time = duration_cast<milliseconds>(end - start).count() / 1000.0;

    return vector(recommendations.begin(), recommendations.begin() + min(10, (int)recommendations.size()));
}

// 复杂度分析输出
void print_complexity(const Complexity& analysis) {
    cout << "\n=== 复杂度分析 ===" << endl;
    cout << "数据统计:" << endl;
    cout << "用户数: " << analysis.user_count << endl;
    cout << "电影数: " << analysis.movie_count << endl;
    cout << "评分记录数: " << analysis.rating_count << endl;
    cout << "标签数: " << analysis.tag_count << endl;
    cout << "\n实际耗时:" << endl;
    cout << "数据加载耗时: " << analysis.load_time << "秒" << endl;
    cout << "推荐生成耗时: " << analysis.recommend_time << "秒" << endl;
}

int main() {
    Complexity analysis;
    auto total_start = high_resolution_clock::now();

    auto movies = load_movies("movies.dat", analysis);
    unordered_map<int, User> users;
    unordered_map<int, vector<int>> movie_users;

    try {
        load_ratings("ratings.dat", users, movie_users, movies, analysis);
        load_tags("tags.dat", users, analysis);
    }
    catch (const exception& e) {
        cerr << "数据加载错误: " << e.what() << endl;
        return 1;
    }

    // 构建特征并训练PQ模型
    ProductQuantization* pq = nullptr;
    vector<int> user_ids;
    unordered_map<int, int> uid_to_index;
    build_features_and_train_pq(users, movies, pq, user_ids, uid_to_index, analysis);

    if (!users.empty()) {
        int target_user = users.begin()->first;
        cout << "\n正在为用户 " << target_user << " 生成推荐..." << endl;

        auto recommendations = generate_recommendations(
            target_user, users, movie_users, movies, *pq, uid_to_index, user_ids, analysis);

        cout << "\n用户 " << target_user << " 的TOP10推荐:" << endl;
        for (const auto& [mid, score] : recommendations) {
            cout << " 电影ID: " << mid
                << " | 片名: " << movies.at(mid).title
                << " | 预测评分: " << fixed << setprecision(1) << score << endl;
        }
    }
    else {
        cout << "警告: 未找到有效用户数据" << endl;
    }

    // 释放PQ内存
    if (pq) delete pq;

    // 输出分析结果
    print_complexity(analysis);
    cout << "\n总执行时间: "
        << duration_cast<milliseconds>(high_resolution_clock::now() - total_start).count() / 1000.0
        << "秒" << endl;

    return 0;
}
